{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure to drought\n",
    "\n",
    "\n",
    "A simple accepted measure for drought is the Standardized Precipitation Index (SPI). Similar to indicators 1.1 and 1.2, this indicator is not a direct measure of health impacts of drought, but rather a measure of the risk factor, which is mediated by a range of complicated causes to health. In general, the claim is that increase in this indicator represents an increased risk, which may lead directly to negative impacts on health or require adaptation measures to mitigate negative impacts.\n",
    "\n",
    "Agnew, C.T., Using the SPI to identify drought propose SPI thresholds:\n",
    "\n",
    "| SPI      | Category         |\n",
    "|----------|------------------|\n",
    "| >= -0.84 | Normal           | \n",
    "| < -0.84  | Moderate Drought |\n",
    "| < -1.28  | Severe drought   | \n",
    "| < -1.65  | Extreme drought  |\n",
    "\n",
    "\n",
    "\n",
    "Select the locations experiencing 'Severe' drought on the 3-month basis. Define the drought indicator as 'number of months in drought' for a given year.\n",
    "\n",
    "\n",
    "\n",
    "## Literature on selection of drought index\n",
    "\n",
    "In 2009, the World Meteorological Organization (WMO) approved the Lincoln Declaration on Drought Indices (LDDI). The LDDI recommends that \"the Standardized Precipitation Index (SPI) be used to characterize the meteorological droughts around the world\", in addition to other drought indices that were in use in their service. In support of this recommendation, it was suggested that a \"comprehensive user manual\" describing the SPI should be developed. The manual provides a description of the index, the computation methods, specific examples of where it is currently being used, the strengths and limitations and mapping capabilities.\n",
    "\n",
    "https://www.ncl.ucar.edu/Applications/spi.shtml\n",
    "\n",
    "https://climatedataguide.ucar.edu/climate-data/standardized-precipitation-index-spi\n",
    "\n",
    "\n",
    "Note this one also good for extreme rain\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/978-94-015-9265-9_2\n",
    "\n",
    "## SPI drought index\n",
    "\n",
    ">TODO formula\n",
    "\n",
    "Python code:\n",
    "\n",
    "https://www.drought.gov/drought/python-climate-indices\n",
    "\n",
    "\n",
    "Also an implementation in NCL\n",
    "https://www.ncl.ucar.edu/Applications/spi.shtml\n",
    "\n",
    "Could apply directly to source files\n",
    "\n",
    "https://www.ncl.ucar.edu/Document/Functions/Built-in/dim_spi_n.shtml\n",
    "\n",
    "\n",
    "> NOTE the implementation from drought.gov looks modern and good (built with Numba, which suggests they know what they are doing and like modern approaches which should make life easier). Should be able to run directly on netCDF files from ECMWF.\n",
    "\n",
    "\n",
    "## Data for SPI\n",
    "\n",
    "Monthly summary data for PPT\n",
    "\n",
    "NOTE that I have already a 1949-2012 summary of SPI. Do I really need to build my own? The main advantage is to ensure coherance across indicators and that they can be easily updated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from scipy import stats\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "\n",
    "import weather_ecmwf\n",
    "import population_tools\n",
    "\n",
    "from config import DATA_SRC, WEATHER_SRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPT_FILES = WEATHER_SRC / 'ecmwf' / 'monthly_precipitation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial calculation using the already generated SPI file for 1949-2012\n",
    "\n",
    "This could be good to deliver initial values this year, although it would be best to adapt to using the ECMWF dataset to be able to update regularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_file = DATA_SRC / 'weather' / 'spi3_6_12_1deg_cru_ts_3_21_1949_2012.nc'\n",
    "droughts = spi.spi3.where(spi.spi3 < -1.28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drought_projection(droughts):\n",
    "    with population_tools.PopulationProjector() as pop:\n",
    "        years = list(range(2000,2013))\n",
    "\n",
    "        droughts_pop = xr.concat((pop.project(year, droughts.sel(year=year)) for year in years)\n",
    "                                 , dim='time')\n",
    "        pop_sum = pop.data.population.sum(dim=['latitude', 'longitude'])\n",
    "        return droughts_pop.compute(), pop_sum.compute()\n",
    "    \n",
    "droughts_pop, pop_sum = get_drought_projection(droughts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droughts_pop_ts = (droughts_pop / pop_sum).sum(dim=['latitude', 'longitude'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SPI calculation to ECMWF monthly precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error: /Users/jonathanchambers/Data/weather/ecmwf/monthly_precipitation/1980_precipitation.nc is not a valid NetCDF 3 file\n            If this is a NetCDF4 file, you may need to install the\n            netcdf4 library, e.g.,\n\n            $ pip install netcdf4\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/lancet/lib/python3.6/site-packages/xarray/backends/scipy_.py\u001b[0m in \u001b[0;36m_open_scipy_netcdf\u001b[0;34m(filename, mode, mmap, version)\u001b[0m\n\u001b[1;32m     81\u001b[0m         return scipy.io.netcdf_file(filename, mode=mode, mmap=mmap,\n\u001b[0;32m---> 82\u001b[0;31m                                     version=version)\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# netcdf3 message is obscure in this case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lancet/lib/python3.6/site-packages/scipy/io/netcdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, mmap, version, maskandscale)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'ra'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lancet/lib/python3.6/site-packages/scipy/io/netcdf.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    585\u001b[0m             raise TypeError(\"Error: %s is not a valid NetCDF 3 file\" %\n\u001b[0;32m--> 586\u001b[0;31m                             self.filename)\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'version_byte'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'>b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Error: /Users/jonathanchambers/Data/weather/ecmwf/monthly_precipitation/1980_precipitation.nc is not a valid NetCDF 3 file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c4ac46f2b11d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweather_ecmwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweather_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPT_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Lancet/health-climate-exposure/weather_ecmwf.py\u001b[0m in \u001b[0;36mweather_mfdataset\u001b[0;34m(root_path, rename)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweather_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*.nc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scipy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncdf_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_name\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mWEATHER_NAMES\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncdf_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lancet/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, lock, data_vars, coords, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     datasets = [open_dataset(p, engine=engine, chunks=chunks or {}, lock=lock,\n\u001b[0;32m--> 553\u001b[0;31m                              **kwargs) for p in paths]\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0mfile_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_obj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lancet/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     datasets = [open_dataset(p, engine=engine, chunks=chunks or {}, lock=lock,\n\u001b[0;32m--> 553\u001b[0;31m                              **kwargs) for p in paths]\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0mfile_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_obj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lancet/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             store = backends.ScipyDataStore(filename_or_obj,\n\u001b[0;32m--> 289\u001b[0;31m                                             autoclose=autoclose)\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pydap'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPydapDataStore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lancet/lib/python3.6/site-packages/xarray/backends/scipy_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename_or_obj, mode, format, group, writer, mmap, autoclose)\u001b[0m\n\u001b[1;32m    132\u001b[0m                                    \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                                    mode=mode, mmap=mmap, version=version)\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_isopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lancet/lib/python3.6/site-packages/xarray/backends/scipy_.py\u001b[0m in \u001b[0;36m_open_scipy_netcdf\u001b[0;34m(filename, mode, mmap, version)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \"\"\"\n\u001b[1;32m     92\u001b[0m             \u001b[0merrmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Error: /Users/jonathanchambers/Data/weather/ecmwf/monthly_precipitation/1980_precipitation.nc is not a valid NetCDF 3 file\n            If this is a NetCDF4 file, you may need to install the\n            netcdf4 library, e.g.,\n\n            $ pip install netcdf4\n            "
     ]
    }
   ],
   "source": [
    "weather_ecmwf.weather_mfdataset(PPT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lancet]",
   "language": "python",
   "name": "conda-env-lancet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
